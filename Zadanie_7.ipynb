{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpar5LziY_-0"
      },
      "source": [
        "# Zadanie 7 (7 pkt)\n",
        "Celem zadania jest zaimplementowanie dwóch wersji naiwnego klasyfikatora Bayesa.\n",
        "* W pierwszej wersji należy dokonać dyskretyzacji danych - przedział wartości każdego atrybutu dzielimy na cztery równe przedziały i każdej ciągłej wartości atrybutu przypisujemy wartość dyskretną wynikająca z przynależności do danego przedziału.\n",
        "* W drugiej wersji wartości likelihood wyliczamy z rozkładów normalnych o średnich i odchyleniach standardowych wynikających z wartości atrybutów.\n",
        "Trening i test należy przeprowadzić dla zbioru Iris, tak jak w przypadku zadania z drzewem klasyfikacyjnym. Proszę przeprowadzić eksperymenty najpierw dla DOKŁADNIE takiego podziału zbioru testowego i treningowego jak umieszczony poniżej. W dalszej części należy przeprowadzić analizę działania klasyfikatorów dla różnych wartości parametrów. Proszę korzystać z przygotowanego szkieletu programu, oczywiście można go modyfikować według potrzeb. Wszelkie elementy szkieletu zostaną wyjaśnione na zajęciach.\n",
        "\n",
        "* Dyskretyzacja danych - **0.5 pkt**\n",
        "* Implementacja funkcji rozkładu normalnego o zadanej średniej i odchyleniu standardowym. - **0.5 pkt**\n",
        "* Implementacja naiwnego klasyfikatora Bayesa dla danych dyskretnych. - **2.0 pkt**\n",
        "* Implementacja naiwnego klasyfikatora Bayesa dla danych ciągłych. - **2.5 pkt**\n",
        "* Przeprowadzenie eksperymentów, wnioski i sposób ich prezentacji. - **1.5 pkt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fBh2tfQ44u5k"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=123)\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.likelihoods = {}\n",
        "\n",
        "    def build_classifier(self, train_features, train_classes):\n",
        "        self.priors = Counter(train_classes)\n",
        "        train_features = np.array([self.data_discretization(attribute) for attribute in train_features.T]).T\n",
        "        self.likelihoods = np.zeros(shape=(len(self.priors), len(train_features[0]), 4))\n",
        "        for features, result_class in zip(train_features, train_classes):\n",
        "            for i in enumerate(features):\n",
        "                self.likelihoods[result_class][i[0]][features[i[0]]] += 1\n",
        "        total = self.priors.total()\n",
        "        for key in self.priors.keys():\n",
        "            key_occurances = self.priors[key]\n",
        "            self.priors[key] /= total\n",
        "            for i in enumerate(train_features[0]):\n",
        "                for j in range(4):\n",
        "                    self.likelihoods[key][i[0]][j] = (self.likelihoods[key][i[0]][j] + 1) / (key_occurances + 4)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def data_discretization(data):\n",
        "        max_value = max(data)\n",
        "        min_value = min(data)\n",
        "        section_size = (max_value - min_value) / 4\n",
        "        first_section_limit = min_value + section_size\n",
        "        second_section_limit = first_section_limit + section_size\n",
        "        third_section_limit = second_section_limit + section_size\n",
        "        discretize = lambda x: 0 if x < first_section_limit else 1 if x < second_section_limit else 2 if x < third_section_limit else 3\n",
        "        return [discretize(x) for x in data]\n",
        "        \n",
        "\n",
        "    def predict(self, sample):\n",
        "        max_probability = 0\n",
        "        prediction = None\n",
        "        for key in self.priors.keys():\n",
        "            probability = self.priors[key]\n",
        "            for i in enumerate(sample):\n",
        "                probability *= (self.likelihoods[key][i[0]][sample[i[0]]])\n",
        "            if probability > max_probability:\n",
        "                prediction = key\n",
        "                max_probability = probability\n",
        "        return prediction\n",
        "\n",
        "class GaussianNaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.likelihoods = {}\n",
        "\n",
        "    def build_classifier(self, train_features, train_classes):\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def normal_dist(x, mean, std):\n",
        "        pass\n",
        "\n",
        "    def predict(self, sample):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 1\n",
            "2 2\n",
            "2 2\n",
            "1 1\n",
            "0 0\n",
            "2 2\n",
            "1 1\n",
            "0 0\n",
            "0 0\n",
            "1 1\n",
            "2 2\n",
            "0 0\n",
            "1 1\n",
            "2 2\n",
            "2 2\n",
            "0.9333333333333333\n"
          ]
        }
      ],
      "source": [
        "good = 0\n",
        "total = 0\n",
        "x_test = np.array([NaiveBayes.data_discretization(r) for r in x_test.T]).T\n",
        "nb = NaiveBayes()\n",
        "nb.build_classifier(x_train, y_train)\n",
        "for a, b in zip(x_test, y_test):\n",
        "    n = nb.predict(a)\n",
        "    print(n, b)\n",
        "    if n == b:\n",
        "        good += 1\n",
        "    total += 1\n",
        "print(good/total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test[0]\n",
        "nb.predict(np.array([2,0,3,2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
